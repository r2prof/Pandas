{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH 03 - Creating and Persisting DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 10, 'display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, we create a DataFrame from an existing file or a database, but we can also create\n",
    "# one from scratch. We can create a DataFrame from parallel lists of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = ['Paul', 'John', 'Richard', 'George']\n",
    "lname = ['McCartney', 'Lennon', 'Starkey', 'Harrison']\n",
    "birth = [1942, 1940, 1940, 1943]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from the lists, mapping the column name to the list:\n",
    "\n",
    "people = {'first': fname, 'last': lname, 'birth': birth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Starkey</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first       last  birth\n",
       "0     Paul  McCartney   1942\n",
       "1     John     Lennon   1940\n",
       "2  Richard    Starkey   1940\n",
       "3   George   Harrison   1943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the dictionary:\n",
    "\n",
    "beatles = pd.DataFrame(people)\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By default, pandas will create a RangeIndex for our DataFrame when we call the constructor:\n",
    "\n",
    "beatles.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can specify another index for the DataFrame if we desire:\n",
    "\n",
    "pd.DataFrame(people, index=['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There\\'s More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also create a DataFrame from a list of dictionaries:\n",
    "\n",
    "pd.DataFrame(\n",
    "[{\"first\":\"Paul\",\"last\":\"McCartney\", \"birth\":1942},\n",
    " {\"first\":\"John\",\"last\":\"Lennon\", \"birth\":1940},\n",
    " {\"first\":\"Richard\",\"last\":\"Starkey\", \"birth\":1940},\n",
    " {\"first\":\"George\",\"last\":\"Harrison\", \"birth\":1943}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing CSV\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the DataFrame to a CSV file\n",
    "\n",
    "from io import StringIO\n",
    "fout = StringIO()\n",
    "beatles.to_csv(fout)  # use a filename instead of fout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fout.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There\\'s More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .to_csv method has a few options. You will notice that it included the index in the\n",
    "# output but did not give the index a column name. If you were to read this CSV file into\n",
    "# a DataFrame using the read_csv function, it would not use this as the index by default.\n",
    "\n",
    "# Instead, you will get a column named Unnamed: 0 in addition to an index. These columns\n",
    "# are redundant:\n",
    "\n",
    "_ = fout.seek(0)\n",
    "pd.read_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fout: It represents a file on the filesystem.\n",
    "\n",
    "# seek(0): The seek method is used to change the current file position. In this case, seek(0) \n",
    "# is setting the file pointer to the beginning of the file (offset 0).\n",
    "\n",
    "# _ = : The underscore _ is a convention in Python often used as a throwaway variable name when \n",
    "# the value of the variable is not going to be used. It indicates that the result of the seek(0) \n",
    "# operation is being ignored or not explicitly used in the code.\n",
    "\n",
    "# So, the overall effect of this line of code is to move the file pointer to the beginning of the \n",
    "# file represented by the fout object. This can be useful, for example, when you want to read the \n",
    "# contents of the file again from the start or overwrite its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The read_csv function has an index_col parameter that you can use to specify the\n",
    "# location of the index:\n",
    "\n",
    "_ = fout.seek(0)\n",
    "pd.read_csv(fout, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternatively, if we didn't want to include the index when writing the CSV file, we can set the\n",
    "# index parameter to False:\n",
    "\n",
    "fout = StringIO()\n",
    "beatles.to_csv(fout, index=False) \n",
    "print(fout.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pandas library is an in-memory tool. You need to be able to fit your data in memory to use\n",
    "# pandas with it. If you come across a large CSV file that you want to process, you have a few\n",
    "# options. \n",
    "\n",
    "# If you can process portions of it at a time, you can read it into chunks and process\n",
    "# each chunk. Alternatively, if you know that you should have enough memory to load the file,\n",
    "# there are a few hints to help pare down the file size.\n",
    "\n",
    "# Note that in general, you should have three to ten times the amount of memory as the size\n",
    "# of the DataFrame that you want to manipulate. Extra memory should give you enough extra\n",
    "# space to perform many of the common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading large CSV files\n",
    "# Determine how much memory the whole file will take up. We will use the nrows\n",
    "# parameter of read_csv to limit how much data we load to a small sample:\n",
    "\n",
    "diamonds = pd.read_csv('../data/diamonds.csv', nrows=1000)\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the .info method to see how much memory the sample of data uses:\n",
    "\n",
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that 1,000 rows use about 78.2 KB of memory. If we had 1 billion\n",
    "# rows, that would take about 78 GB of memory. It turns out that it is possible to rent\n",
    "# machines in the cloud that have that much memory but let's see if we can take it\n",
    "# down a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the dtype parameter to read_csv to tell it to use the correct (or smaller) numeric types:\n",
    "\n",
    "diamonds2 = pd.read_csv('../data/diamonds.csv', nrows=1000,\n",
    "    dtype={'carat': np.float32, 'depth': np.float32,\n",
    "           'table': np.float32, 'x': np.float32,\n",
    "           'y': np.float32, 'z': np.float32,\n",
    "           'price': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By changing the numeric types, we use about 62% of the memory.\n",
    "\n",
    "diamonds2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the dtype parameter to use change object types to categoricals. First, inspect\n",
    "# the .value_counts method of the object columns. If they are low cardinality, you\n",
    "# can convert them to categorical columns to save even more memory:\n",
    "\n",
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By changing the numeric types, we use about 62% of the memory. Note that we lose\n",
    "# some precision, which may or may not be acceptable.\n",
    "\n",
    "diamonds2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the dtype parameter to use change object types to categoricals. First, inspect\n",
    "# the .value_counts method of the object columns. If they are low cardinality, you\n",
    "# can convert them to categorical columns to save even more memory:\n",
    "\n",
    "diamonds2.cut.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds2.color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds2.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Because these are of low cardinality, we can convert them to categoricals and use\n",
    "# around 37% of the original size:\n",
    "\n",
    "diamonds3 = pd.read_csv('../data/diamonds.csv', nrows=1000,\n",
    "    dtype={'carat': np.float32, 'depth': np.float32,\n",
    "           'table': np.float32, 'x': np.float32,\n",
    "           'y': np.float32, 'z': np.float32,\n",
    "           'price': np.int16,\n",
    "           'cut': 'category', 'color': 'category',\n",
    "           'clarity': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are columns that we know we can ignore, we can use the usecols\n",
    "# parameter to specify the columns we want to load. Here, we will ignore columns x, y,\n",
    "# and z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price']\n",
    "diamonds4 = pd.read_csv('../data/diamonds.csv', nrows=1000,\n",
    "    dtype={'carat': np.float32, 'depth': np.float32,\n",
    "           'table': np.float32, 'price': np.int16,\n",
    "           'cut': 'category', 'color': 'category',\n",
    "           'clarity': 'category'},\n",
    "    usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price']\n",
    "diamonds_iter = pd.read_csv('../data/diamonds.csv', nrows=1000,\n",
    "    dtype={'carat': np.float32, 'depth': np.float32,\n",
    "           'table': np.float32, 'price': np.int16,\n",
    "           'cut': 'category', 'color': 'category',\n",
    "           'clarity': 'category'},\n",
    "    usecols=cols,\n",
    "    chunksize=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    return f'processed {df.size} items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in diamonds_iter:\n",
    "    process(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column turns out to be non-numeric, pandas will convert it to an object column, and\n",
    "# treat the values as strings. String values in pandas take up a bunch of memory as each value\n",
    "# is stored as a Python string. If we convert these to categoricals, pandas will use much less\n",
    "# memory as it only stores the string once, rather than creating new strings (even if they repeat)\n",
    "# for every row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\\..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There\\'s more \\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds.price.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds.price.memory_usage(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds.cut.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds.cut.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds4.to_feather('../tmp/d.arr')\n",
    "diamonds5 = pd.read_feather('../tmp/d.arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamonds4.to_parquet('../tmp/d.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beatles.to_excel('../tmp/beat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "beatles.to_excel('../tmp/beat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Paul</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Starkey</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>George</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    first       last  birth\n",
       "0           0     Paul  McCartney   1942\n",
       "1           1     John     Lennon   1940\n",
       "2           2  Richard    Starkey   1940\n",
       "3           3   George   Harrison   1943"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Excel file with the read_excel function:\n",
    "\n",
    "beat2 = pd.read_excel('../tmp/beat.xlsx')\n",
    "beat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Starkey</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first       last  birth\n",
       "0     Paul  McCartney   1942\n",
       "1     John     Lennon   1940\n",
       "2  Richard    Starkey   1940\n",
       "3   George   Harrison   1943"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because this file had an index column included, you can specify that with the index_\n",
    "# col parameter:\n",
    "\n",
    "beat2 = pd.read_excel('../tmp/beat.xlsx', index_col=0)\n",
    "beat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first    object\n",
       "last     object\n",
       "birth     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beat2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\\..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There\\'s more\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How to write files to Excel\n",
    "\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can use pandas to write to a sheet of a spreadsheet. You can pass a sheet_name\n",
    "# parameter to the .to_excel method to tell it the name of the sheet to create:\n",
    "\n",
    "xl_writer = pd.ExcelWriter('../tmp/beat.xlsx')\n",
    "beatles.to_excel(xl_writer, sheet_name='All')\n",
    "beatles[beatles.birth < 1941].to_excel(xl_writer, sheet_name='1940')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the ZIP files\\...\n",
    "#### Not clear - Do it again and find some good resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrels08</th>\n",
       "      <th>barrelsA08</th>\n",
       "      <th>charge120</th>\n",
       "      <th>charge240</th>\n",
       "      <th>city08</th>\n",
       "      <th>...</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>startStop</th>\n",
       "      <th>phevCity</th>\n",
       "      <th>phevHwy</th>\n",
       "      <th>phevComb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.695714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.207778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.347895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   barrels08  barrelsA08  charge120  charge240  city08  ...  \\\n",
       "0  15.695714         0.0        0.0        0.0      19  ...   \n",
       "1  29.964545         0.0        0.0        0.0       9  ...   \n",
       "2  12.207778         0.0        0.0        0.0      23  ...   \n",
       "3  29.964545         0.0        0.0        0.0      10  ...   \n",
       "4  17.347895         0.0        0.0        0.0      17  ...   \n",
       "\n",
       "                     modifiedOn  startStop  phevCity  phevHwy  phevComb  \n",
       "0  Tue Jan 01 00:00:00 EST 2013        NaN         0        0         0  \n",
       "1  Tue Jan 01 00:00:00 EST 2013        NaN         0        0         0  \n",
       "2  Tue Jan 01 00:00:00 EST 2013        NaN         0        0         0  \n",
       "3  Tue Jan 01 00:00:00 EST 2013        NaN         0        0         0  \n",
       "4  Tue Jan 01 00:00:00 EST 2013        NaN         0        0         0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  If the CSV file is the only file in the ZIP file, you can just call the read_csv function on it:\n",
    "\n",
    "autos = pd.read_csv('../data/vehicles.csv.zip', low_memory=False)\n",
    "autos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, autos.modifiedOn.dtype is checking the data type of the column named modifiedOn in the autos dataset. \n",
    "# The data type could be one of several possibilities, such as integer, float, string, datetime, etc.\n",
    "\n",
    "autos.modifiedOn.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One thing to be aware of is that if you have date columns in the CSV file, they will be\n",
    "# left as strings. You have two options to convert them. You can use the parse_dates\n",
    "# parameter from read_csv and convert them when loading the file. Alternatively, you\n",
    "# can use the more powerful to_datetime function after loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Tue Jan 01 00:00:00 EST 2013\n",
       "1        Tue Jan 01 00:00:00 EST 2013\n",
       "2        Tue Jan 01 00:00:00 EST 2013\n",
       "3        Tue Jan 01 00:00:00 EST 2013\n",
       "4        Tue Jan 01 00:00:00 EST 2013\n",
       "                     ...             \n",
       "39096    Tue Jan 01 00:00:00 EST 2013\n",
       "39097    Tue Jan 01 00:00:00 EST 2013\n",
       "39098    Tue Jan 01 00:00:00 EST 2013\n",
       "39099    Tue Jan 01 00:00:00 EST 2013\n",
       "39100    Tue Jan 01 00:00:00 EST 2013\n",
       "Name: modifiedOn, Length: 39101, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos.modifiedOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# pd.to_datetime(autos.modifiedOn)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autos = pd.read_csv('../data/vehicles.csv.zip',\n",
    "#    parse_dates=['modifiedOn'])  # doctest: +SKIP\n",
    "# autos.modifiedOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#  If the ZIP file has many files it in, reading a CSV file from it is a little more involved.\n",
    "# The read_csv function does not have the ability to specify a file inside a ZIP file.\n",
    "# Instead, we will use the zipfile module from the Python standard library.\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multipleChoiceResponses.csv\n",
      "freeFormResponses.csv\n",
      "SurveySchema.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23906/1021377863.py:3: DtypeWarning: Columns (0,2,8,10,21,23,24,25,26,27,28,42,44,54,56,64,81,83,85,87,105,107,109,121,123,125,148,150,157,172,174,192,194,210,218,219,221,223,246,247,249,262,264,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,302,304,306,325,326,329,341,368,371,384,385,389,390,391,393,394) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  kag = pd.read_csv(z.open('multipleChoiceResponses.csv'))\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('../data/kaggle-survey-2018.zip') as z:\n",
    "    print('\\n'.join(z.namelist()))\n",
    "    kag = pd.read_csv(z.open('multipleChoiceResponses.csv'))\n",
    "    kag_questions = kag.iloc[0]\n",
    "    survey = kag.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            1          2\n",
      "Time from Start to Finish (seconds)                       710        434\n",
      "Q1                                                     Female       Male\n",
      "Q1_OTHER_TEXT                                              -1         -1\n",
      "Q2                                                      45-49      30-34\n",
      "Q3                                   United States of America  Indonesia\n",
      "...                                                       ...        ...\n",
      "Q50_Part_5                                                NaN        NaN\n",
      "Q50_Part_6                                                NaN        NaN\n",
      "Q50_Part_7                                                NaN        NaN\n",
      "Q50_Part_8                                                NaN        NaN\n",
      "Q50_OTHER_TEXT                                             -1         -1\n",
      "\n",
      "[395 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(survey.head(2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with databases\\..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Lite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite database, which is included with Python. However, Python has the ability to connect \n",
    "# with most SQL databases and pandas, in turn, can leverage that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('../data/beat.db')\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"\"\"DROP TABLE Band\"\"\")\n",
    "    cur.execute(\"\"\"CREATE TABLE Band(id INTEGER PRIMARY KEY,\n",
    "        fname TEXT, lname TEXT, birthyear INT)\"\"\")\n",
    "    cur.execute(\"\"\"INSERT INTO Band VALUES(\n",
    "        0, 'Paul', 'McCartney', 1942)\"\"\")\n",
    "    cur.execute(\"\"\"INSERT INTO Band VALUES(\n",
    "        1, 'John', 'Lennon', 1940)\"\"\")\n",
    "    _ = con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3282\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3262\u001b[0m \n\u001b[1;32m   3263\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \n\u001b[1;32m   3281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m engine \u001b[38;5;241m=\u001b[39m sa\u001b[38;5;241m.\u001b[39mcreate_engine(\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///data/beat.db\u001b[39m\u001b[38;5;124m'\u001b[39m, echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m sa_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3258\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3237\u001b[0m \n\u001b[1;32m   3238\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \n\u001b[1;32m   3256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_cls(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    148\u001b[0m             err, dialect, engine\n\u001b[1;32m    149\u001b[0m         )\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2422\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2421\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    148\u001b[0m             err, dialect, engine\n\u001b[1;32m    149\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3282\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3262\u001b[0m \n\u001b[1;32m   3263\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \n\u001b[1;32m   3281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    710\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/sqlalchemy/engine/default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "engine = sa.create_engine(\n",
    "  'sqlite:///data/beat.db', echo=True)\n",
    "sa_connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "beat = pd.read_sql('Band', sa_connection, index_col='id')\n",
    "beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sql = '''SELECT fname, birthyear from Band'''\n",
    "fnames = pd.read_sql(sql, con)\n",
    "fnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON \n",
    "#### JavaScript Object Notation (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript Object Notation (JSON) is a common format used for transferring data over the\n",
    "# internet. Contrary to the name, it does not require JavaScript to read or create. The Python\n",
    "# standard library ships with the json library that will encode and decode from JSON:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it work\\'s\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'people' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m encoded \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(people)\n\u001b[1;32m      3\u001b[0m encoded\n",
      "\u001b[0;31mNameError\u001b[0m: name 'people' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "encoded = json.dumps(people)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "json.loads(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "beatles = pd.read_json(encoded)\n",
    "beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "records = beatles.to_json(orient='records')\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_json(records, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "split = beatles.to_json(orient='split')\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_json(split, orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "index = beatles.to_json(orient='index')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_json(index, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "values = beatles.to_json(orient='values')\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_json(values, orient='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "(pd.read_json(values, orient='values')\n",
    "   .rename(columns=dict(enumerate(['first', 'last', 'birth'])))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "table = beatles.to_json(orient='table')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "pd.read_json(table, orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\\..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There\\'s more\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "output = beat.to_dict()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "output['version'] = '0.4.1'\n",
    "json.dumps(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading HTML Tables\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the read_html function to load all of the tables from: \n",
    "# https://en.wikipedia.org/wiki/The_Beatles_discography:\n",
    "\n",
    "url ='https://en.wikipedia.org/wiki/The_Beatles_discography'\n",
    "dfs = pd.read_html(url)\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The Beatles discography</th>\n",
       "      <th>The Beatles discography.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Beatles in 1965</td>\n",
       "      <td>The Beatles in 1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Studio albums</td>\n",
       "      <td>12 (UK), 17 (US)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Live albums</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compilation albums</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Video albums</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Music videos</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPs</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Singles</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mash-ups</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Box sets</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The Beatles discography The Beatles discography.1\n",
       "0     The Beatles in 1965       The Beatles in 1965\n",
       "1           Studio albums          12 (UK), 17 (US)\n",
       "2             Live albums                         5\n",
       "3      Compilation albums                        51\n",
       "4            Video albums                        22\n",
       "5            Music videos                        53\n",
       "6                     EPs                        36\n",
       "7                 Singles                        63\n",
       "8                Mash-ups                         2\n",
       "9                Box sets                        17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://en.wikipedia.org/wiki/The_Beatles_discography'\n",
    "dfs = pd.read_html(url, match='List of studio albums', na_values='—')\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(               'Title',            'Title'),\n",
       "            (    'Album details[A]', 'Album details[A]'),\n",
       "            ('Peak chart positions',        'UK [7][8]'),\n",
       "            ('Peak chart positions',          'AUS [9]'),\n",
       "            ('Peak chart positions',         'CAN [10]'),\n",
       "            ('Peak chart positions',         'FRA [11]'),\n",
       "            ('Peak chart positions',         'GER [12]'),\n",
       "            ('Peak chart positions',         'NOR [13]'),\n",
       "            ('Peak chart positions',      'US [14][15]'),\n",
       "            (      'Certifications',   'Certifications'),\n",
       "            (               'Sales',            'Sales')],\n",
       "           )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://en.wikipedia.org/wiki/The_Beatles_discography'\n",
    "dfs = pd.read_html(url, match='List of studio albums', na_values='—',\n",
    "    header=[0,1])\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Album details[A]</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Peak chart positions</th>\n",
       "      <th>Certifications</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Album details[A]</th>\n",
       "      <th>UK [7][8]</th>\n",
       "      <th>AUS [9]</th>\n",
       "      <th>CAN [10]</th>\n",
       "      <th>...</th>\n",
       "      <th>GER [12]</th>\n",
       "      <th>NOR [13]</th>\n",
       "      <th>US [14][15]</th>\n",
       "      <th>Certifications</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please Please Me</td>\n",
       "      <td>Released: 22 March 1963 Label: Parlophone</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>BPI: Platinum[16] ARIA: Gold[17] MC: Gold[18] ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With the Beatles[B]</td>\n",
       "      <td>Released: 22 November 1963 Label: Parlophone (...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179</td>\n",
       "      <td>BPI: Gold[16] ARIA: Gold[17] BVMI: Gold[20] MC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Hard Day's Night</td>\n",
       "      <td>Released: 10 July 1964 Label: Parlophone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BPI: Platinum[16] ARIA: Gold[17]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beatles for Sale</td>\n",
       "      <td>Released: 4 December 1964 Label: Parlophone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BPI: Gold[16] ARIA: Gold[17] MC: Gold[18] RIAA...</td>\n",
       "      <td>UK: 750,000[21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Released: 6 August 1965 Label: Parlophone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BPI: Platinum[16] ARIA: Gold[17]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Beatles (\"The White Album\")</td>\n",
       "      <td>Released: 22 November 1968 Label: Apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BPI: 2× Platinum[16] ARIA: 2× Platinum[17] MC:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yellow Submarine[C]</td>\n",
       "      <td>Released: 17 January 1969 Label: Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BPI: Gold[16] MC: Gold[18] RIAA: Platinum[19]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Abbey Road</td>\n",
       "      <td>Released: 26 September 1969 Label: Apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BPI: 8× Platinum[16] ARIA: 3× Platinum[17] BVM...</td>\n",
       "      <td>UK: 2,240,608[26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Released: 8 May 1970 Label: Apple</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BPI: Platinum[16] ARIA: Platinum[17] MC: 3× Pl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "      <td>\"—\" denotes that the recording did not chart o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "                                                Title   \n",
       "0                                    Please Please Me   \n",
       "1                                 With the Beatles[B]   \n",
       "2                                  A Hard Day's Night   \n",
       "3                                    Beatles for Sale   \n",
       "4                                               Help!   \n",
       "..                                                ...   \n",
       "8                     The Beatles (\"The White Album\")   \n",
       "9                                 Yellow Submarine[C]   \n",
       "10                                         Abbey Road   \n",
       "11                                          Let It Be   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                     Album details[A]  \\\n",
       "                                     Album details[A]   \n",
       "0           Released: 22 March 1963 Label: Parlophone   \n",
       "1   Released: 22 November 1963 Label: Parlophone (...   \n",
       "2            Released: 10 July 1964 Label: Parlophone   \n",
       "3         Released: 4 December 1964 Label: Parlophone   \n",
       "4           Released: 6 August 1965 Label: Parlophone   \n",
       "..                                                ...   \n",
       "8             Released: 22 November 1968 Label: Apple   \n",
       "9              Released: 17 January 1969 Label: Apple   \n",
       "10           Released: 26 September 1969 Label: Apple   \n",
       "11                  Released: 8 May 1970 Label: Apple   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                 Peak chart positions  \\\n",
       "                                            UK [7][8]   \n",
       "0                                                   1   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   1   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "8                                                   1   \n",
       "9                                                   3   \n",
       "10                                                  1   \n",
       "11                                                  1   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                                       \\\n",
       "                                              AUS [9]   \n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                   1   \n",
       "3                                                   1   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "8                                                   1   \n",
       "9                                                   4   \n",
       "10                                                  1   \n",
       "11                                                  1   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                                       ...  \\\n",
       "                                             CAN [10]  ...   \n",
       "0                                                 NaN  ...   \n",
       "1                                                 NaN  ...   \n",
       "2                                                 NaN  ...   \n",
       "3                                                 NaN  ...   \n",
       "4                                                 NaN  ...   \n",
       "..                                                ...  ...   \n",
       "8                                                   1  ...   \n",
       "9                                                   1  ...   \n",
       "10                                                  1  ...   \n",
       "11                                                  1  ...   \n",
       "12  \"—\" denotes that the recording did not chart o...  ...   \n",
       "\n",
       "                                                       \\\n",
       "                                             GER [12]   \n",
       "0                                                   5   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   1   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "8                                                   1   \n",
       "9                                                   5   \n",
       "10                                                  1   \n",
       "11                                                  4   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                                       \\\n",
       "                                             NOR [13]   \n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "8                                                   1   \n",
       "9                                                   1   \n",
       "10                                                  1   \n",
       "11                                                  1   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                                       \\\n",
       "                                          US [14][15]   \n",
       "0                                                 155   \n",
       "1                                                 179   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "8                                                   1   \n",
       "9                                                   2   \n",
       "10                                                  1   \n",
       "11                                                  1   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                       Certifications  \\\n",
       "                                       Certifications   \n",
       "0   BPI: Platinum[16] ARIA: Gold[17] MC: Gold[18] ...   \n",
       "1   BPI: Gold[16] ARIA: Gold[17] BVMI: Gold[20] MC...   \n",
       "2                    BPI: Platinum[16] ARIA: Gold[17]   \n",
       "3   BPI: Gold[16] ARIA: Gold[17] MC: Gold[18] RIAA...   \n",
       "4                    BPI: Platinum[16] ARIA: Gold[17]   \n",
       "..                                                ...   \n",
       "8   BPI: 2× Platinum[16] ARIA: 2× Platinum[17] MC:...   \n",
       "9       BPI: Gold[16] MC: Gold[18] RIAA: Platinum[19]   \n",
       "10  BPI: 8× Platinum[16] ARIA: 3× Platinum[17] BVM...   \n",
       "11  BPI: Platinum[16] ARIA: Platinum[17] MC: 3× Pl...   \n",
       "12  \"—\" denotes that the recording did not chart o...   \n",
       "\n",
       "                                                Sales  \n",
       "                                                Sales  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                     UK: 750,000[21]  \n",
       "4                                                 NaN  \n",
       "..                                                ...  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                  UK: 2,240,608[26]  \n",
       "11                                                NaN  \n",
       "12  \"—\" denotes that the recording did not chart o...  \n",
       "\n",
       "[13 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(               'Title',            'Title'),\n",
       "            (    'Album details[A]', 'Album details[A]'),\n",
       "            ('Peak chart positions',        'UK [7][8]'),\n",
       "            ('Peak chart positions',          'AUS [9]'),\n",
       "            ('Peak chart positions',         'CAN [10]'),\n",
       "            ('Peak chart positions',         'FRA [11]'),\n",
       "            ('Peak chart positions',         'GER [12]'),\n",
       "            ('Peak chart positions',         'NOR [13]'),\n",
       "            ('Peak chart positions',      'US [14][15]'),\n",
       "            (      'Certifications',   'Certifications'),\n",
       "            (               'Sales',            'Sales')],\n",
       "           )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 11 elements, new values have 10 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelease\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCAN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGER\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCertifications\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/miniconda3/envs/neo/lib/python3.11/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 11 elements, new values have 10 elements"
     ]
    }
   ],
   "source": [
    "df = dfs[0]\n",
    "df.columns = ['Title', 'Release', 'UK', 'AUS', 'CAN', 'FRA', 'GER',\n",
    "    'NOR', 'US', 'Certifications']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "res = (df\n",
    "  .pipe(lambda df_: df_[~df_.Title.str.startswith('Released')])\n",
    "  .iloc[:-1]\n",
    "  .assign(release_date=lambda df_: pd.to_datetime(\n",
    "             df_.Release.str.extract(r'Released: (.*) Label')\n",
    "               [0]\n",
    "               .str.replace(r'\\[E\\]', '')\n",
    "          ),\n",
    "          label=lambda df_:df_.Release.str.extract(r'Label: (.*)')\n",
    "         )\n",
    "   .loc[:, ['Title', 'UK', 'AUS', 'CAN', 'FRA', 'GER', 'NOR',\n",
    "            'US', 'release_date', 'label']]\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\\..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/mattharrison/datasets/blob/master/data/anscombes.csv'\n",
    "dfs = pd.read_html(url, attrs={'class': 'csv-data'})\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
