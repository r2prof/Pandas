{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH-04: Beginning Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 6, 'display.max_rows', 6, 'display.max_colwidth', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a data analysis routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "college = pd.read_csv('../data/college.csv')\n",
    "college.sample(random_state=42)\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the dimensions of the DataFrame with the .shape attribute:\n",
    "\n",
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List the data type of each column, the number of non-missing values, and memory\n",
    "# usage with the .info method:\n",
    "\n",
    "college.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get summary statistics for the numerical columns and transpose the DataFrame \n",
    "# for more readable output:\n",
    "\n",
    "college.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "college.describe(include=[pd.Categorical]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "college.describe(include=[object]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# It is possible to specify the exact quantiles returned from the .describe method \n",
    "# when used with numeric columns:\n",
    "\n",
    "college.describe(include=[np.number],\n",
    "   percentiles=[.01, .05, .10, .25, .5,\n",
    "                .75, .9, .95, .99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A crucial part of data analysis involves creating and maintaining a data dictionary. \n",
    "\n",
    "# A data dictionary is a table of metadata and notes on each column of data. One of the \n",
    "# primary purposes of a data dictionary is to explain the meaning of the column names. \n",
    "\n",
    "# The college dataset uses a lot of abbreviations that are likely to be unfamiliar to an \n",
    "# analyst who is inspecting it for the first time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# A data dictionary for the college dataset is provided in the following college_data_\n",
    "# dictionary.csv file:\n",
    "\n",
    "pd.read_csv('../data/college_data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing memory by changing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reading in our college dataset, we select a few columns of different data types\n",
    "# that will clearly show how much memory may be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "college = pd.read_csv('../data/college.csv')\n",
    "different_cols = ['RELAFFIL', 'SATMTMID', 'CURROPER', 'INSTNM', 'STABBR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command is selecting all rows from the DataFrame college but only \n",
    "# the columns specified in the different_cols variable. \n",
    "\n",
    "# The variable different_cols is expected to contain the column labels that \n",
    "# you want to extract from the DataFrame.\n",
    "\n",
    "col2 = college.loc[:, different_cols]\n",
    "col2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#  Inspect the data types of each column:\n",
    "\n",
    "col2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Find the memory usage of each column with the .memory_usage method:\n",
    "\n",
    "original_mem = col2.memory_usage(deep=True)\n",
    "original_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# There is no need to use 64 bits for the RELAFFIL column as it contains only 0 or 1.\n",
    "# Let's convert this column to an 8-bit (1 byte) integer with the .astype method:\n",
    "\n",
    "col2['RELAFFIL'] = col2['RELAFFIL'].astype(np.int8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "col2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "college[different_cols].memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# To save even more memory, you will want to consider changing object data types to\n",
    "# categorical if they have a reasonably low cardinality (number of unique values). Let's\n",
    "# first check the number of unique values for both the object columns:\n",
    "\n",
    "\n",
    "col2.select_dtypes(include=['object']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# The STABBR column is a good candidate to convert to categorical as less than one\n",
    "# percent of its values are unique:\n",
    "\n",
    "col2['STABBR'] = col2['STABBR'].astype('category')\n",
    "col2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compute the memory usage again:\n",
    "\n",
    "new_mem = col2.memory_usage(deep=True)\n",
    "new_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Finally, let's compare the original memory usage with our updated memory usage.\n",
    "# The RELAFFIL column is, as expected, an eighth of its original size, while the\n",
    "# STABBR column has shrunk to just three percent of its original size:\n",
    "\n",
    "new_mem / original_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the smallest of the largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This recipe can be used to create catchy news headlines such as Out of the Top 100\n",
    "# Universities, These 5 have the Lowest Tuition, or From the Top 50 Cities to Live, \n",
    "# these 10 are the Most Affordable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During analysis, it is possible that you will first need to find a grouping of data \n",
    "# that contains the top n values in a single column and, from this subset, find the \n",
    "# bottom m values based on a different column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this recipe, we find the five lowest budget movies from the top 100 scoring \n",
    "# movies by taking advantage of the convenience methods: .nlargest and .nsmallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.9</td>\n",
       "      <td>237000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates ...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>300000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.8</td>\n",
       "      <td>245000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>250000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star War...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_title  imdb_score       budget\n",
       "0       Avatar         7.9  237000000.0\n",
       "1  Pirates ...         7.1  300000000.0\n",
       "2      Spectre         6.8  245000000.0\n",
       "3  The Dark...         8.5  250000000.0\n",
       "4  Star War...         7.1          NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('../data/movie.csv')\n",
    "movie2 = movie[['movie_title', 'imdb_score', 'budget']]\n",
    "movie2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>Towering...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>The Shaw...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>25000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>The Godf...</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>Dekalog</td>\n",
       "      <td>9.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>Kickboxe...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>17000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_title  imdb_score      budget\n",
       "2725  Towering...         9.5         NaN\n",
       "1920  The Shaw...         9.3  25000000.0\n",
       "3402  The Godf...         9.2   6000000.0\n",
       "2779      Dekalog         9.1         NaN\n",
       "4312  Kickboxe...         9.1  17000000.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the .nlargest method to select the top 100 movies by imdb_score\n",
    "\n",
    "movie2.nlargest(100, 'imdb_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>Butterfl...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>Children...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>12 Angry...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>A Separa...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>The Othe...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_title  imdb_score    budget\n",
       "4804  Butterfl...         8.7  180000.0\n",
       "4801  Children...         8.5  180000.0\n",
       "4706  12 Angry...         8.9  350000.0\n",
       "4550  A Separa...         8.4  500000.0\n",
       "4636  The Othe...         8.4  500000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain the .nsmallest method to return the five lowest budget films among those with a top 100 score:\n",
    "\n",
    "(movie2\n",
    "  .nlargest(100, 'imdb_score')\n",
    "  .nsmallest(5, 'budget')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first parameter of the .nlargest method, n, must be an integer and selects the \n",
    "# number of rows to be returned. The second parameter, columns, takes a column name \n",
    "# as a string.\n",
    "\n",
    "# Step 2 returns the 100 highest-scoring movies. We could have saved this intermediate \n",
    "# result as its own variable but instead, we chain the .nsmallest method to it in step 3, \n",
    "# which returns exactly five rows, sorted by budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to pass a list of column names to the columns parameter of the .nlargest\n",
    "# and .nsmallest methods. This would only be useful to break ties in the event that there\n",
    "# were duplicate values sharing the nth ranked spot in the first column in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the largest of each group by sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the most basic and common operations to perform during data analysis is to select\n",
    "# rows containing the largest value of some column within a group. For instance, this would be\n",
    "# like finding the highest-rated film of each year or the highest-grossing film by content rating.\n",
    "\n",
    "# To accomplish this task, we need to sort the groups as well as the column used to rank each\n",
    "# member of the group, and then extract the highest member of each group.\n",
    "\n",
    "# In this recipe, we will find the highest-rated film of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie = pd.read_csv('../data/movie.csv')\n",
    "movie[['movie_title', 'title_year', 'imdb_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the .sort_values method to sort the DataFrame by title_year. The default behavior sorts from the smallest to the largest. \n",
    "# Use the ascending=True parameter to invert this behavior:\n",
    "\n",
    "(movie\n",
    "  [['movie_title', 'title_year', 'imdb_score']]\n",
    "  .sort_values('title_year', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To sort multiple columns at once, use a list.\n",
    "\n",
    "(movie\n",
    "  [['movie_title', 'title_year', 'imdb_score']]\n",
    "  .sort_values(['title_year','imdb_score'],\n",
    "               ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We use the .drop_duplicates method to keep only the first row of every year:\n",
    "\n",
    "(movie\n",
    "  [['movie_title', 'title_year', 'imdb_score']]\n",
    "  .sort_values(['title_year','imdb_score'],\n",
    "               ascending=False)\n",
    "  .drop_duplicates(subset='title_year')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works... Group by Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "(movie\n",
    "  [['movie_title', 'title_year', 'imdb_score']]\n",
    "  .groupby('title_year', as_index=False)\n",
    "  .apply(lambda df: df.sort_values('imdb_score',\n",
    "         ascending=False).head(1))\n",
    "  .sort_values('title_year', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "(movie\n",
    "  [['movie_title', 'title_year',\n",
    "    'content_rating', 'budget']]\n",
    "   .sort_values(['title_year',\n",
    "       'content_rating', 'budget'],\n",
    "       ascending=[False, False, True])\n",
    "   .drop_duplicates(subset=['title_year',\n",
    "        'content_rating'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating nlargest with sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .sort_values to replicate the first part of the expression and grab the first 100 rows with the .head method\n",
    "\n",
    "movie = pd.read_csv('../data/movie.csv')\n",
    "(movie\n",
    "   [['movie_title', 'imdb_score', 'budget']]\n",
    "   .nlargest(100, 'imdb_score') \n",
    "   .nsmallest(5, 'budget')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "(movie\n",
    "   [['movie_title', 'imdb_score', 'budget']]\n",
    "   .sort_values('imdb_score', ascending=False)\n",
    "   .head(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we have the top 100 scoring movies, we can use .sort_values with .head again to grab the lowest five by budget\n",
    "\n",
    "(movie\n",
    "   [['movie_title', 'imdb_score', 'budget']]\n",
    "   .sort_values('imdb_score', ascending=False)\n",
    "   .head(100) \n",
    "   .sort_values('budget')\n",
    "   .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "(movie\n",
    "   [['movie_title', 'imdb_score', 'budget']]\n",
    "   .nlargest(100, 'imdb_score')\n",
    "   .tail()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "(movie\n",
    "   [['movie_title', 'imdb_score', 'budget']]\n",
    "   .sort_values('imdb_score', ascending=False) \n",
    "   .head(100)\n",
    "   .tail()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a trailing stop order price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#import pandas_datareader.data as web\n",
    "import requests_cache\n",
    "session = requests_cache.CachedSession(\n",
    "   cache_name='cache', backend='sqlite', \n",
    "   expire_after=datetime.timedelta(days=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tsla = web.DataReader('tsla', data_source='yahoo',\n",
    "   start='2017-1-1', session=session)\n",
    "tsla.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tsla_close = tsla['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tsla_cummax = tsla_close.cummax()\n",
    "tsla_cummax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "(tsla\n",
    "  ['Close']\n",
    "  .cummax()\n",
    "  .mul(.9)\n",
    "  .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### There's more..."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
